{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "from rbm import RBM\n",
    "from sampler import VanillaSampler, PartitionedSampler\n",
    "from trainer import VanillaTrainier\n",
    "from performance import Result\n",
    "import numpy as np\n",
    "import datasets, performance, plotter, mnist, pickle, rbm, os, logging, sampler\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "logger = logging.getLogger()\n",
    "# Set the logging level to logging.DEBUG \n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# make one 2 bit image, both visibles on\n",
    "v = np.ones(2)\n",
    "\n",
    "# lets make our hiddens, 2 hidden units\n",
    "h_a = np.zeros(2)\n",
    "h_b = np.zeros(2)\n",
    "h_a[0] = 1\n",
    "h_a[1] = 0\n",
    "\n",
    "h_b[0] = 0\n",
    "h_b[1] = 1\n",
    "\n",
    "# Set up our weights matrix (|h| , |v|), with perfect weights.\n",
    "w_a = np.ones((2, 2))\n",
    "w_b = np.ones((2, 2))\n",
    "w_a[0][1] = -1\n",
    "w_a[1][0] = -1\n",
    "w_b[0][1] = -1\n",
    "w_b[1][0] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = RBM(2,2,1)\n",
    "B = RBM(2,2,1)\n",
    "# manually set our RBM's\n",
    "A.hidden = h_a\n",
    "B.hidden = h_b\n",
    "A.visible = v\n",
    "B.visible = v\n",
    "A.weights = w_a\n",
    "B.weights = w_b\n",
    "A.hidden_bias = 0.5\n",
    "B.hidden_bias = 0.5\n",
    "A.visible_bias = 0.5\n",
    "B.visible_bias = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def count_matrix_for_runs(runs, model, visible):\n",
    "    van_sampler = VanillaSampler(model)\n",
    "    counts = {}\n",
    "    for i in range(runs):\n",
    "\n",
    "        vis = np.where(van_sampler.hidden_to_visible(van_sampler.visible_to_hidden(visible)) >= 0.5, 1, 0)\n",
    "        key = np.array_str(vis)\n",
    "        if key in counts:\n",
    "            counts[key] = counts[key] + 1\n",
    "        else:\n",
    "            counts[key] = 0\n",
    "    for key in counts:\n",
    "        counts[key] = counts[key]/runs * 100\n",
    "    \n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'[1 0]': 23.46, '[1 1]': 52.43, '[0 1]': 24.08}\n",
      "{'[1 0]': 23.810000000000002, '[1 1]': 53.410000000000004, '[0 1]': 22.75}\n"
     ]
    }
   ],
   "source": [
    "# run vanilla sampling 10,000 times, getting the percentage of reconstructions for A and then B\n",
    "print(count_matrix_for_runs(10000, A, v))\n",
    "print(count_matrix_for_runs(10000, B, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def weighted_sum_into_vis(vis_idx, w,h):\n",
    "    return np.dot(w.T, h)\n",
    "\n",
    "def visible_to_hidden(visible):\n",
    "    np.dot(w.T,visibe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def __bernouli_flip__(weighted_sum):\n",
    "        p = expit(weighted_sum) > np.random.rand(*weighted_sum.shape)\n",
    "        return np.where(p, 1, 0)\n",
    "    \n",
    "def calc_correction(hidden_a, hidden_b, weights_a, weights_b):        \n",
    "    phi_a = np.dot(hidden_a, weights_a)\n",
    "    phi_b = np.dot(hidden_b, weights_b)\n",
    "\n",
    "    on_weights_a = (hidden_a * weights_a)\n",
    "    off_weights_a = (1 - hidden_a) * weights_a\n",
    "\n",
    "    on_weights_b =  (hidden_b * weights_b)\n",
    "    off_weights_b = (1 - hidden_b) * weights_b\n",
    "    \n",
    "    j_off_a = phi_a - on_weights_a\n",
    "    j_off_b = phi_b - on_weights_b\n",
    "    j_on_a = phi_a + off_weights_a\n",
    "    j_on_b = phi_b + off_weights_b\n",
    "    \n",
    "    correction_a = np.log(expit(j_off_a))  - np.log(expit((j_off_a + phi_b))) + np.log(expit((j_on_a + phi_b))) - np.log(expit(j_on_a))\n",
    "    correction_b = np.log(expit(j_off_b))  - np.log(expit((j_off_b + phi_a))) + np.log(expit((j_on_b + phi_a))) - np.log(expit(j_on_b))\n",
    "    #print(\"calc'd\\nc_a{}\\t for h_a{}\\nc_b{}\\t for h_b{}\".format(correction_a, h_a, correction_b, h_b))\n",
    "    return correction_a, correction_b\n",
    "\n",
    "\n",
    "\n",
    "def run_partitioned_samples(hidden_a, hidden_b, weights_a, weights_b, visible,num_samples, vis_bias_a, vis_bias_b, hid_bias_a, hid_bias_b):\n",
    "    for epoch in range(num_samples):\n",
    "\n",
    "        phi_a = np.dot(hidden_a, weights_a) + vis_bias_a\n",
    "        phi_b = np.dot(hidden_b, weights_b) + vis_bias_b\n",
    "        \n",
    "        correction_a, correction_b = calc_correction(hidden_a, hidden_b, weights_a, weights_b)\n",
    "        \"\"\"\n",
    "        Apply the correction to the weighted sum into the hiddens\n",
    "        \"\"\"\n",
    "        psi_a = (visible * weights_a.T + correction_a).sum(1) + hid_bias_a\n",
    "        psi_b = (visible * weights_b.T + correction_b).sum(1) + hid_bias_b\n",
    "\n",
    "        # now, do we turn on he hiddens? Bernoulli sample to decide\n",
    "        hidden_a = __bernouli_flip__(psi_a)\n",
    "        hidden_b = __bernouli_flip__(psi_b)\n",
    "\n",
    "    return hidden_a, hidden_b\n",
    "\n",
    "def runit(times, sample_times,h_a, h_b, w_a, w_b,v):\n",
    "    wins = []\n",
    "    for i in range(times):\n",
    "        h_a, h_b = run_partitioned_samples(h_a,h_b, w_a,w_b, v, sample_times, 0, 0,0,0)\n",
    "        wins.append((h_a != h_b).all())\n",
    "        \n",
    "    return wins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that $$ \\psi_{j} = \\sum_i W_{ji} (v_i  + \\sigma_{ij}^A - \\sigma_{ij}^{AB}) $$\n",
    "And therefore we would expect:\n",
    "$$ \\psi_{j=0} = \\sum_i W_{0i} (v_i  + \\sigma_{i0}^A - \\sigma_{i0}^{AB}) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_a[1 1] h_b[1 1]\n"
     ]
    }
   ],
   "source": [
    "h_a, h_b = run_partitioned_samples(h_a,h_b, w_a,w_b, v, 500, 0.5, 0.5,0.5,0.5)\n",
    "print(\"h_a{} h_b{}\".format(h_a, h_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wins:57 losses:143\n"
     ]
    }
   ],
   "source": [
    "# do 200 runs of partitioned sampling with each run finding the hidden state with 10,000 gibbs alternations\n",
    "wins = runit(200,10000, h_a, h_b, w_a,w_b,v)\n",
    "win_count = np.array(wins).sum()\n",
    "lose_count = len(wins) - win_count\n",
    "print(\"wins:{} losses:{}\".format(win_count, lose_count))\n",
    "# damn we wanted to wins to be greater than the losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c_a, c_b = calc_correction(np.array([1,1]), np.array([0,1]), w_a, w_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\psi_{j} = \\sum_{i} (W_{ji}v_i + C_{ji}) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def approx_correction(h_a, h_b, w_a, w_b, v_bias, h_bias):\n",
    "    phi_a = np.dot(w_a, h_a)\n",
    "    phi_b = np.dot(w_b, h_b)\n",
    "    sig_A = phi_a + w_a/2\n",
    "    sig_B = phi_b + w_b/2\n",
    "    epsilon_a = np.dot(w_b,h_b)\n",
    "    epsilon_b = np.dot(w_a,h_a)\n",
    "    sig_AB = sig_A + epsilon_a\n",
    "    sig_BA = sig_B + epsilon_b\n",
    "    c_a = expit(sig_A) - expit(sig_AB)\n",
    "    c_b = expit(sig_B) - expit(sig_BA)\n",
    "    return c_a, c_b\n",
    "\n",
    "def psi(h_a, h_b, w_a, w_b, v_bias = 0.5, h_bias = 0.5):\n",
    "    c_a, c_b = approx_correction(h_a, h_b, w_a, w_b, v_bias, h_bias)\n",
    "    psi_a = (w_a * (v + c_a)).sum(1)\n",
    "    psi_b = (w_b * (v + c_b)).sum(1)\n",
    "    return psi_a,psi_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.39023029, -0.48983732]), array([-0.48983732,  0.39023029]))"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psi(np.array([1,0]), np.array([0,1]), w_a, w_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.48983732, -0.39023029]), array([ 0.,  0.]))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psi(np.array([1,1]), np.array([0,1]), w_a, w_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.48983732, -0.39023029]), array([ 0.,  0.]))"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psi(np.array([0,0]), np.array([0,1]), w_a, w_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.,  0.]), array([-0.39023029,  0.48983732]))"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psi(np.array([1,0]), np.array([1,1]), w_a, w_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.21313469,  0.39023029]), array([-0.21313469,  0.39023029]))"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psi(np.array([1,0]), np.array([1,0]), w_a, w_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.39023029, -0.21313469]), array([ 0.39023029, -0.21313469]))"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psi(np.array([0,1]), np.array([0,1]), w_a, w_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.,  0.]), array([ 0.,  0.]))"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psi(np.array([1,1]), np.array([1,1]), w_a, w_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.,  0.]), array([ 0.,  0.]))"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psi(np.array([0,0]), np.array([0,0]), w_a, w_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
